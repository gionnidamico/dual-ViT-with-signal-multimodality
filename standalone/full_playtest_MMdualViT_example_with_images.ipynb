{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# FINGERPRINT\n",
    "# \"\"\"\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from functools import partial\n",
    "\n",
    "# from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "# from timm.models.registry import register_model\n",
    "# from timm.models.vision_transformer import _cfg\n",
    "# import math\n",
    "# import numpy as np\n",
    "\n",
    "# def rand_bbox(size, lam, scale=1):\n",
    "\n",
    "\n",
    "# class ClassAttention(nn.Module):\n",
    "\n",
    "\n",
    "# class FFN(nn.Module):\n",
    "\n",
    "\n",
    "# class ClassBlock(nn.Module):\n",
    "\n",
    "\n",
    "# class PVT2FFN(nn.Module):\n",
    "\n",
    "\n",
    "# class MergeFFN(nn.Module):\n",
    "\n",
    "\n",
    "# class Attention(nn.Module):\n",
    "\n",
    "\n",
    "# class DualAttention(nn.Module):\n",
    "\n",
    "\n",
    "# class MergeBlock(nn.Module):\n",
    "\n",
    "\n",
    "# class DualBlock(nn.Module):\n",
    "\n",
    "\n",
    "# class DownSamples(nn.Module):\n",
    "\n",
    "\n",
    "# class Stem(nn.Module):\n",
    "\n",
    "\n",
    "# class SemanticEmbed(nn.Module):\n",
    "\n",
    "\n",
    "# class DualViT(nn.Module):\n",
    "\n",
    "\n",
    "# class DWConv(nn.Module):\n",
    "\n",
    "\n",
    "# @register_model\n",
    "# def dualvit_s(pretrained=False, **kwargs):\n",
    "#     model = DualViT(\n",
    "#         stem_hidden_dim = 32,\n",
    "#         embed_dims = [64, 128, 320, 448], \n",
    "#         num_heads = [2, 4, 10, 14], \n",
    "#         mlp_ratios = [8, 8, 4, 3, 2],\n",
    "#         norm_layer = partial(nn.LayerNorm, eps=1e-6), \n",
    "#         depths = [3, 4, 6, 3], \n",
    "#         **kwargs)\n",
    "#     model.default_cfg = _cfg()\n",
    "#     return model\n",
    "\n",
    "# @register_model\n",
    "# def dualvit_b(pretrained=False, **kwargs):\n",
    "#     model = DualViT(\n",
    "#         stem_hidden_dim = 64,\n",
    "#         embed_dims = [64, 128, 320, 512], \n",
    "#         num_heads = [2, 4, 10, 16], \n",
    "#         mlp_ratios = [8, 8, 4, 3, 2],\n",
    "#         norm_layer = partial(nn.LayerNorm, eps=1e-6), \n",
    "#         depths = [3, 4, 15, 3], \n",
    "#         **kwargs)\n",
    "#     model.default_cfg = _cfg()\n",
    "#     return model\n",
    "\n",
    "# @register_model\n",
    "# def dualvit_l(pretrained=False, **kwargs):\n",
    "#     model = DualViT(\n",
    "#         stem_hidden_dim = 64,\n",
    "#         embed_dims = [96, 192, 384, 512], \n",
    "#         num_heads = [3, 6, 12, 16], \n",
    "#         mlp_ratios = [8, 8, 4, 3, 2],\n",
    "#         norm_layer = partial(nn.LayerNorm, eps=1e-6), \n",
    "#         depths = [3, 6, 21, 3], \n",
    "#         **kwargs)\n",
    "#     model.default_cfg = _cfg()\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GjVQnXXMPOAc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\damic\\anaconda3\\envs\\vision\\lib\\site-packages\\torchvision\\io\\image.py:14: UserWarning: Failed to load image Python extension: '[WinError 1920] Impossibile accedere al file'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.vision_transformer import _cfg\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def rand_bbox(size, lam, scale=1):\n",
    "    W = size[1] // scale\n",
    "    H = size[2] // scale\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "class ClassAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.head_dim = head_dim\n",
    "        self.scale = head_dim**-0.5\n",
    "        self.kv = nn.Linear(dim, dim * 2)\n",
    "        self.q = nn.Linear(dim, dim)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            if m.weight is not None:\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        kv = self.kv(x).reshape(B, N, 2, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
    "        k, v = kv[0], kv[1]\n",
    "        q = self.q(x[:, :1, :]).reshape(B, self.num_heads, 1, self.head_dim)\n",
    "        attn = ((q * self.scale) @ k.transpose(-2, -1))\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        cls_embed = (attn @ v).transpose(1, 2).reshape(B, 1, self.head_dim * self.num_heads)\n",
    "        cls_embed = self.proj(cls_embed)\n",
    "        return cls_embed\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(hidden_features, in_features)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class ClassBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        self.attn = ClassAttention(dim, num_heads)\n",
    "        self.mlp = FFN(dim, int(dim * mlp_ratio))\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        cls_embed = x[:, :1]\n",
    "        cls_embed = cls_embed + self.attn(self.norm1(x))\n",
    "        cls_embed = cls_embed + self.mlp(self.norm2(cls_embed))\n",
    "        return torch.cat([cls_embed, x[:, 1:]], dim=1)\n",
    "\n",
    "class PVT2FFN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.dwconv = DWConv(hidden_features)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(hidden_features, in_features)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, H, W):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dwconv(x, H, W)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class MergeFFN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.dwconv = DWConv(hidden_features)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(hidden_features, in_features)\n",
    "\n",
    "        self.fc_proxy = nn.Sequential(\n",
    "            nn.Linear(in_features, 2*in_features),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(2*in_features, in_features),\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            if m.weight is not None:\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, H, W):\n",
    "        x, semantics = torch.split(x, [H*W, x.shape[1] - H*W], dim=1)\n",
    "        semantics = self.fc_proxy(semantics)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dwconv(x, H, W)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.cat([x, semantics], dim=1)\n",
    "        return x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads):\n",
    "        super().__init__()\n",
    "        assert dim % num_heads == 0, f\"dim {dim} should be divided by num_heads {num_heads}.\"\n",
    "\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.q = nn.Linear(dim, dim)\n",
    "        self.kv = nn.Linear(dim, dim * 2)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, H, W):\n",
    "        B, N, C = x.shape\n",
    "        q = self.q(x).reshape(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)\n",
    "        kv = self.kv(x).reshape(B, -1, 2, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        k, v = kv[0], kv[1]\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class DualAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads, drop_path=0.0):\n",
    "        super().__init__()\n",
    "        assert dim % num_heads == 0, f\"dim {dim} should be divided by num_heads {num_heads}.\"\n",
    "\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.q = nn.Linear(dim, dim)\n",
    "        self.kv = nn.Linear(dim, dim * 2)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "\n",
    "        self.q_proxy = nn.Linear(dim, dim)\n",
    "        self.kv_proxy = nn.Linear(dim, dim * 2)\n",
    "        self.q_proxy_ln = nn.LayerNorm(dim)\n",
    "\n",
    "        self.p_ln = nn.LayerNorm(dim)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "        self.mlp_proxy = nn.Sequential(\n",
    "            nn.Linear(dim, 4 * dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * dim, dim),\n",
    "        )\n",
    "        self.proxy_ln = nn.LayerNorm(dim)\n",
    "\n",
    "        self.qkv_proxy = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, dim*3)\n",
    "        )\n",
    "\n",
    "        layer_scale_init_value = 1e-6\n",
    "        self.gamma1 = nn.Parameter(layer_scale_init_value * torch.ones((dim)),\n",
    "            requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.gamma2 = nn.Parameter(layer_scale_init_value * torch.ones((dim)),\n",
    "            requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.gamma3 = nn.Parameter(layer_scale_init_value * torch.ones((dim)),\n",
    "            requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            if m.weight is not None:\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def selfatt(self, semantics):\n",
    "        B, N, C = semantics.shape\n",
    "        qkv = self.qkv_proxy(semantics).reshape(B, -1, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        semantics = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        return semantics\n",
    "\n",
    "    def forward(self, x, H, W, semantics):\n",
    "        semantics = semantics + self.drop_path(self.gamma1 * self.selfatt(semantics))\n",
    "\n",
    "        B, N, C = x.shape\n",
    "        B_p, N_p, C_p = semantics.shape\n",
    "        q = self.q(x).reshape(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)\n",
    "        q_semantics = self.q_proxy(self.q_proxy_ln(semantics)).reshape(B_p, N_p, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)\n",
    "\n",
    "        kv_semantics = self.kv_proxy(x).reshape(B, -1, 2, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        kp, vp = kv_semantics[0], kv_semantics[1]\n",
    "        attn = (q_semantics @ kp.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        _semantics = (attn @ vp).transpose(1, 2).reshape(B, N_p, C) * self.gamma2\n",
    "        semantics = semantics + self.drop_path(_semantics)\n",
    "        semantics = semantics + self.drop_path(self.gamma3 * self.mlp_proxy(self.p_ln(semantics)))\n",
    "\n",
    "        kv = self.kv(self.proxy_ln(semantics)).reshape(B, -1, 2, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        k, v = kv[0], kv[1]\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        return x, semantics\n",
    "\n",
    "class MergeBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio, drop_path=0., norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        self.attn = Attention(dim, num_heads)\n",
    "        self.mlp = MergeFFN(in_features=dim, hidden_features=int(dim * mlp_ratio))\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        \n",
    "        layer_scale_init_value = 1e-6\n",
    "        self.gamma1 = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n",
    "            requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.gamma2 = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n",
    "            requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            if m.weight is not None:\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, H, W):\n",
    "        x = x + self.drop_path(self.gamma1 * self.attn(self.norm1(x), H, W))\n",
    "        x = x + self.drop_path(self.gamma2 * self.mlp(self.norm2(x), H, W))\n",
    "        return x\n",
    "\n",
    "class DualBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio, drop_path=0., norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.norm2 = norm_layer(dim)\n",
    "\n",
    "        self.attn = DualAttention(dim, num_heads, drop_path=drop_path)\n",
    "        self.mlp = PVT2FFN(dim, int(dim * mlp_ratio))\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        \n",
    "        layer_scale_init_value = 1e-6\n",
    "        self.gamma1 = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n",
    "            requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.gamma2 = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n",
    "            requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            if m.weight is not None:\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, H, W, semantics):\n",
    "        _x, semantics = self.attn(self.norm1(x), H, W, semantics)\n",
    "        x = x + self.drop_path(self.gamma1 * _x)\n",
    "        x = x + self.drop_path(self.gamma2 * self.mlp(self.norm2(x), H, W))\n",
    "        return x, semantics\n",
    "\n",
    "class DownSamples(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "        self.norm = nn.LayerNorm(out_channels)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        _, _, H, W = x.shape\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.norm(x)\n",
    "        return x, H, W\n",
    "\n",
    "class Stem(nn.Module):\n",
    "    def __init__(self, in_channels, stem_hidden_dim, out_channels):\n",
    "        super().__init__()\n",
    "        hidden_dim = stem_hidden_dim\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_dim, kernel_size=7, stride=2,\n",
    "                      padding=3, bias=False),  # 112x112\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1,\n",
    "                      padding=1, bias=False),  # 112x112\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1,\n",
    "                      padding=1, bias=False),  # 112x112\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.proj = nn.Conv2d(hidden_dim,\n",
    "                              out_channels,\n",
    "                              kernel_size=3,\n",
    "                              stride=2,\n",
    "                              padding=1)\n",
    "        self.norm = nn.LayerNorm(out_channels)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.proj(x)\n",
    "        _, _, H, W = x.shape\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.norm(x)\n",
    "        return x, H, W\n",
    "\n",
    "class SemanticEmbed(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.proj_proxy = nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels),\n",
    "            nn.LayerNorm(out_channels)\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            if m.weight is not None:\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, semantics):\n",
    "        semantics = self.proj_proxy(semantics)\n",
    "        return semantics\n",
    "\n",
    "class DualViT(nn.Module):\n",
    "    def __init__(self, \n",
    "        in_chans = 3, \n",
    "        num_classes = 1000, \n",
    "        stem_hidden_dim = 32,\n",
    "        embed_dims = [64, 128, 320, 448],\n",
    "        num_heads = [2, 4, 10, 14], \n",
    "        mlp_ratios = [8, 8, 4, 3],\n",
    "        drop_path_rate=0., \n",
    "        norm_layer=nn.LayerNorm,\n",
    "        depths=[3, 4, 6, 3], \n",
    "        num_stages=4, \n",
    "        token_label=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.depths = depths\n",
    "        self.num_stages = num_stages\n",
    "\n",
    "        self.sep_stage = 2\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n",
    "        cur = 0\n",
    "        \n",
    "        for i in range(num_stages):\n",
    "            if i == 0:\n",
    "                patch_embed = Stem(in_chans, stem_hidden_dim, embed_dims[i])\n",
    "            else:\n",
    "                patch_embed = DownSamples(embed_dims[i - 1], embed_dims[i])\n",
    "\n",
    "            if i == 0:\n",
    "                self.q = nn.Parameter(torch.empty((64, embed_dims[0])), requires_grad=True)\n",
    "                self.q_embed = nn.Sequential(\n",
    "                    nn.LayerNorm(embed_dims[0]),\n",
    "                    nn.Linear(embed_dims[0], embed_dims[0])\n",
    "                )\n",
    "                self.pool = nn.AvgPool2d((7,7), stride=7)\n",
    "                self.kv = nn.Linear(embed_dims[0], 2*embed_dims[0])\n",
    "                self.scale = embed_dims[0] ** -0.5\n",
    "                self.proxy_ln = nn.LayerNorm(embed_dims[0])\n",
    "                self.se = nn.Sequential(\n",
    "                    nn.Linear(embed_dims[0], embed_dims[0]),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(embed_dims[0], 2*embed_dims[0])\n",
    "                )\n",
    "                trunc_normal_(self.q, std=.02)\n",
    "            else:\n",
    "                semantic_embed = SemanticEmbed(\n",
    "                    embed_dims[i - 1], embed_dims[i]\n",
    "                )\n",
    "                setattr(self, f\"proxy_embed{i + 1}\", semantic_embed)\n",
    "\n",
    "            if i >= self.sep_stage:\n",
    "                block = nn.ModuleList([\n",
    "                    MergeBlock(\n",
    "                        dim=embed_dims[i], \n",
    "                        num_heads=num_heads[i], \n",
    "                        mlp_ratio=mlp_ratios[i]-1 if (j%2!=0 and i==2) else mlp_ratios[i],  \n",
    "                        drop_path=dpr[cur + j], \n",
    "                        norm_layer=norm_layer)\n",
    "                for j in range(depths[i])])\n",
    "            else:\n",
    "                block = nn.ModuleList([\n",
    "                    DualBlock(\n",
    "                        dim=embed_dims[i], \n",
    "                        num_heads=num_heads[i], \n",
    "                        mlp_ratio=mlp_ratios[i],\n",
    "                        drop_path=dpr[cur + j], \n",
    "                        norm_layer=norm_layer)\n",
    "                for j in range(depths[i])])\n",
    "\n",
    "            norm = norm_layer(embed_dims[i])\n",
    "            norm_proxy = norm_layer(embed_dims[i])\n",
    "            cur += depths[i]\n",
    "\n",
    "            setattr(self, f\"patch_embed{i + 1}\", patch_embed)\n",
    "            setattr(self, f\"block{i + 1}\", block)\n",
    "            setattr(self, f\"norm{i + 1}\", norm)\n",
    "\n",
    "            if i != num_stages - 1:\n",
    "                setattr(self, f\"norm_proxy{i + 1}\", norm_proxy)\n",
    "\n",
    "        post_layers = ['ca']\n",
    "        self.post_network = nn.ModuleList([\n",
    "            ClassBlock(\n",
    "                dim = embed_dims[-1], \n",
    "                num_heads = num_heads[-1], \n",
    "                mlp_ratio = mlp_ratios[-1],\n",
    "                norm_layer=norm_layer\n",
    "            )\n",
    "            for i in range(len(post_layers))\n",
    "        ])\n",
    "\n",
    "        # classification head\n",
    "        self.head = nn.Linear(embed_dims[-1], num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "        ##################################### token_label #####################################\n",
    "        self.return_dense = token_label\n",
    "        self.mix_token = token_label\n",
    "        self.beta = 1.0\n",
    "        self.pooling_scale = 8\n",
    "        if self.return_dense:\n",
    "            self.aux_head = nn.Linear(\n",
    "                embed_dims[-1],\n",
    "                num_classes) if num_classes > 0 else nn.Identity()\n",
    "        ##################################### token_label #####################################\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward_cls(self, x):\n",
    "        B, N, C = x.shape\n",
    "        cls_tokens = x.mean(dim=1, keepdim=True)  #self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        for block in self.post_network:\n",
    "            x = block(x)\n",
    "        return x\n",
    "\n",
    "    def forward_last(self, x, tokenlabeling=False):\n",
    "        if tokenlabeling:\n",
    "            x = self.forward_cls(x)\n",
    "        else:\n",
    "            x = self.forward_cls(x)[:, 0]\n",
    "        norm = getattr(self, f\"norm{self.num_stages}\")\n",
    "        x = norm(x)\n",
    "        return x\n",
    "\n",
    "    def forward_sep(self, x, tokenlabeling=False, H=0, W=0):\n",
    "        B = x.shape[0]\n",
    "        for i in range(self.sep_stage):\n",
    "            patch_embed = getattr(self, f\"patch_embed{i + 1}\")\n",
    "            block = getattr(self, f\"block{i + 1}\")\n",
    "\n",
    "            if tokenlabeling == False or i != 0:\n",
    "                x, H, W = patch_embed(x)\n",
    "            else:\n",
    "                x = x.view(B, H*W, -1)\n",
    "            C = x.shape[-1]\n",
    "            if i == 0:\n",
    "                x_down = self.pool(x.reshape(B, H, W, C).permute(0, 3, 1, 2))\n",
    "                x_down_H, x_down_W = x_down.shape[2:]\n",
    "                x_down = x_down.view(B, C, -1).permute(0, 2, 1)\n",
    "                kv = self.kv(x_down).view(B, -1,  2, C).permute(2, 0, 1, 3)\n",
    "                k, v = kv[0], kv[1]  # B, N, C\n",
    "                \n",
    "                if x_down.shape[1] == self.q.shape[0]:\n",
    "                    self_q = self.q\n",
    "                else:\n",
    "                    self_q = self.q.reshape(8, 8, -1).permute(2, 0, 1)\n",
    "                    self_q = F.interpolate(self_q.unsqueeze(0), size=(x_down_H, x_down_W), mode='bicubic').squeeze(0).permute(1, 2, 0)\n",
    "                    self_q = self_q.reshape(-1, self_q.shape[-1])\n",
    "                \n",
    "                attn = (self.q_embed(self_q) @ k.transpose(-1, -2)) * self.scale   # q: 1, M, C,   k: B, N, C -> B, M, N\n",
    "                attn = attn.softmax(-1)  # B, M, N\n",
    "                semantics = attn @ v   # B, M, C\n",
    "                semantics = semantics.view(B, -1, C)\n",
    "\n",
    "                semantics = torch.cat([semantics.unsqueeze(2), x_down.unsqueeze(2)], dim=2)\n",
    "                se = self.se(semantics.sum(2).mean(1))\n",
    "                se = se.view(B, 2, C).softmax(1)\n",
    "                semantics = (semantics * se.unsqueeze(1)).sum(2)\n",
    "                semantics = self.proxy_ln(semantics)\n",
    "            else:\n",
    "                semantics_embed = getattr(self, f\"proxy_embed{i + 1}\")\n",
    "                semantics = semantics_embed(semantics)\n",
    "\n",
    "            for blk in block:\n",
    "                x, semantics = blk(x, H, W, semantics)\n",
    "\n",
    "            norm = getattr(self, f\"norm{i + 1}\")\n",
    "            x = norm(x)\n",
    "            x = x.reshape(B, H, W, -1).permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "            norm_semantics = getattr(self, f\"norm_proxy{i + 1}\")\n",
    "            semantics = norm_semantics(semantics)\n",
    "                \n",
    "        return x, semantics\n",
    "\n",
    "    def forward_merge(self, x, semantics, tokenlabeling=False):\n",
    "        B = x.shape[0]\n",
    "        for i in range(self.sep_stage, self.num_stages):\n",
    "            patch_embed = getattr(self, f\"patch_embed{i + 1}\")\n",
    "            block = getattr(self, f\"block{i + 1}\")\n",
    "            x, H, W = patch_embed(x)\n",
    "\n",
    "            semantics_embed = getattr(self, f\"proxy_embed{i + 1}\")\n",
    "            semantics = semantics_embed(semantics)\n",
    "            \n",
    "            x = torch.cat([x, semantics], dim=1)\n",
    "            for blk in block:\n",
    "                x = blk(x, H, W)\n",
    "\n",
    "            semantics = x[:, H*W:]\n",
    "            x = x[:, 0:H*W]\n",
    "            \n",
    "            if i != self.num_stages - 1:\n",
    "                norm = getattr(self, f\"norm{i + 1}\")\n",
    "                x = norm(x)\n",
    "                x = x.reshape(B, H, W, -1).permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "                norm_semantics = getattr(self, f\"norm_proxy{i + 1}\")\n",
    "                semantics = norm_semantics(semantics)\n",
    "  \n",
    "        if tokenlabeling:\n",
    "            return torch.cat([x, semantics], dim=1), H, W\n",
    "        else:\n",
    "            return torch.cat([x, semantics], dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.return_dense:\n",
    "            x, semantics = self.forward_sep(x)\n",
    "            x = self.forward_merge(x, semantics)\n",
    "            x = self.forward_last(x)\n",
    "            x = self.head(x)\n",
    "            return x\n",
    "        else:\n",
    "            x, H, W = self.forward_embeddings(x)\n",
    "            # mix token, see token labeling for details.\n",
    "            if self.mix_token and self.training:\n",
    "                lam = np.random.beta(self.beta, self.beta)\n",
    "                patch_h, patch_w = x.shape[1] // self.pooling_scale, x.shape[\n",
    "                    2] // self.pooling_scale\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam, scale=self.pooling_scale)\n",
    "                temp_x = x.clone()\n",
    "                sbbx1,sbby1,sbbx2,sbby2=self.pooling_scale*bbx1,self.pooling_scale*bby1,\\\n",
    "                                        self.pooling_scale*bbx2,self.pooling_scale*bby2\n",
    "                temp_x[:, sbbx1:sbbx2, sbby1:sbby2, :] = x.flip(0)[:, sbbx1:sbbx2, sbby1:sbby2, :]\n",
    "                x = temp_x\n",
    "            else:\n",
    "                bbx1, bby1, bbx2, bby2 = 0, 0, 0, 0\n",
    "            \n",
    "            x, semantics = self.forward_sep(x, True, H, W)\n",
    "            x, H, W = self.forward_merge(x, semantics, True)\n",
    "            x = self.forward_last(x, tokenlabeling=True)\n",
    "\n",
    "            x_cls = self.head(x[:, 0])\n",
    "            x_aux = self.aux_head(\n",
    "                x[:, 1:1+H*W]\n",
    "            )  # generate classes in all feature tokens, see token labeling\n",
    "\n",
    "            if not self.training:\n",
    "                return x_cls + 0.5 * x_aux.max(1)[0]\n",
    "\n",
    "            if self.mix_token and self.training:  # reverse \"mix token\", see token labeling for details.\n",
    "                x_aux = x_aux.reshape(x_aux.shape[0], patch_h, patch_w, x_aux.shape[-1])\n",
    "\n",
    "                temp_x = x_aux.clone()\n",
    "                temp_x[:, bbx1:bbx2, bby1:bby2, :] = x_aux.flip(0)[:, bbx1:bbx2, bby1:bby2, :]\n",
    "                x_aux = temp_x\n",
    "\n",
    "                x_aux = x_aux.reshape(x_aux.shape[0], patch_h * patch_w, x_aux.shape[-1])\n",
    "\n",
    "            return x_cls, x_aux, (bbx1, bby1, bbx2, bby2)\n",
    "\n",
    "    def forward_embeddings(self, x):\n",
    "        patch_embed = getattr(self, f\"patch_embed{0 + 1}\")\n",
    "        x, H, W = patch_embed(x)\n",
    "        x = x.view(x.size(0), H, W, -1)\n",
    "        return x, H, W\n",
    "\n",
    "class DWConv(nn.Module):\n",
    "    def __init__(self, dim=768):\n",
    "        super(DWConv, self).__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, 3, 1, 1, bias=True, groups=dim)\n",
    "\n",
    "    def forward(self, x, H, W):\n",
    "        B, N, C = x.shape\n",
    "        x = x.transpose(1, 2).view(B, C, H, W)\n",
    "        x = self.dwconv(x)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "@register_model\n",
    "def dualvit_s(pretrained=False, **kwargs):\n",
    "    model = DualViT(\n",
    "        stem_hidden_dim = 32,\n",
    "        embed_dims = [64, 128, 320, 448], \n",
    "        num_heads = [2, 4, 10, 14], \n",
    "        mlp_ratios = [8, 8, 4, 3, 2],\n",
    "        norm_layer = partial(nn.LayerNorm, eps=1e-6), \n",
    "        depths = [3, 4, 6, 3], \n",
    "        **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    return model\n",
    "\n",
    "@register_model\n",
    "def dualvit_b(pretrained=False, **kwargs):\n",
    "    model = DualViT(\n",
    "        stem_hidden_dim = 64,\n",
    "        embed_dims = [64, 128, 320, 512], \n",
    "        num_heads = [2, 4, 10, 16], \n",
    "        mlp_ratios = [8, 8, 4, 3, 2],\n",
    "        norm_layer = partial(nn.LayerNorm, eps=1e-6), \n",
    "        depths = [3, 4, 15, 3], \n",
    "        **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    return model\n",
    "\n",
    "@register_model\n",
    "def dualvit_l(pretrained=False, **kwargs):\n",
    "    model = DualViT(\n",
    "        stem_hidden_dim = 64,\n",
    "        embed_dims = [96, 192, 384, 512], \n",
    "        num_heads = [3, 6, 12, 16], \n",
    "        mlp_ratios = [8, 8, 4, 3, 2],\n",
    "        norm_layer = partial(nn.LayerNorm, eps=1e-6), \n",
    "        depths = [3, 6, 21, 3], \n",
    "        **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DualViT(\n",
      "  (q_embed): Sequential(\n",
      "    (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=(7, 7), stride=7, padding=0)\n",
      "  (kv): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (proxy_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (se): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  )\n",
      "  (patch_embed1): Stem(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "    )\n",
      "    (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (block1): ModuleList(\n",
      "    (0-2): 3 x DualBlock(\n",
      "      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): DualAttention(\n",
      "        (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (kv): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (q_proxy): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (kv_proxy): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (q_proxy_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (p_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): Identity()\n",
      "        (mlp_proxy): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "        )\n",
      "        (proxy_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (qkv_proxy): Sequential(\n",
      "          (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): Linear(in_features=64, out_features=192, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (mlp): PVT2FFN(\n",
      "        (fc1): Linear(in_features=64, out_features=512, bias=True)\n",
      "        (dwconv): DWConv(\n",
      "          (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "        )\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "  (norm_proxy1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "  (proxy_embed2): SemanticEmbed(\n",
      "    (proj_proxy): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (patch_embed2): DownSamples(\n",
      "    (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (block2): ModuleList(\n",
      "    (0-3): 4 x DualBlock(\n",
      "      (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): DualAttention(\n",
      "        (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (kv): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (q_proxy): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (kv_proxy): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (q_proxy_ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (p_ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (drop_path): Identity()\n",
      "        (mlp_proxy): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (proxy_ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (qkv_proxy): Sequential(\n",
      "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): Linear(in_features=128, out_features=384, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (mlp): PVT2FFN(\n",
      "        (fc1): Linear(in_features=128, out_features=1024, bias=True)\n",
      "        (dwconv): DWConv(\n",
      "          (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "        )\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "  (norm_proxy2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "  (proxy_embed3): SemanticEmbed(\n",
      "    (proj_proxy): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=320, bias=True)\n",
      "      (1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (patch_embed3): DownSamples(\n",
      "    (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (block3): ModuleList(\n",
      "    (0): MergeBlock(\n",
      "      (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "        (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      )\n",
      "      (mlp): MergeFFN(\n",
      "        (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "        (dwconv): DWConv(\n",
      "          (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "        )\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "        (fc_proxy): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=640, out_features=320, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (1): MergeBlock(\n",
      "      (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "        (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      )\n",
      "      (mlp): MergeFFN(\n",
      "        (fc1): Linear(in_features=320, out_features=960, bias=True)\n",
      "        (dwconv): DWConv(\n",
      "          (dwconv): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
      "        )\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=960, out_features=320, bias=True)\n",
      "        (fc_proxy): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=640, out_features=320, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (2): MergeBlock(\n",
      "      (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "        (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      )\n",
      "      (mlp): MergeFFN(\n",
      "        (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "        (dwconv): DWConv(\n",
      "          (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "        )\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "        (fc_proxy): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=640, out_features=320, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (3): MergeBlock(\n",
      "      (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "        (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      )\n",
      "      (mlp): MergeFFN(\n",
      "        (fc1): Linear(in_features=320, out_features=960, bias=True)\n",
      "        (dwconv): DWConv(\n",
      "          (dwconv): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
      "        )\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=960, out_features=320, bias=True)\n",
      "        (fc_proxy): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=640, out_features=320, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (4): MergeBlock(\n",
      "      (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "        (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      )\n",
      "      (mlp): MergeFFN(\n",
      "        (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "        (dwconv): DWConv(\n",
      "          (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "        )\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "        (fc_proxy): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=640, out_features=320, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (5): MergeBlock(\n",
      "      (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "        (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      )\n",
      "      (mlp): MergeFFN(\n",
      "        (fc1): Linear(in_features=320, out_features=960, bias=True)\n",
      "        (dwconv): DWConv(\n",
      "          (dwconv): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
      "        )\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=960, out_features=320, bias=True)\n",
      "        (fc_proxy): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=640, out_features=320, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "  (norm_proxy3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "  (proxy_embed4): SemanticEmbed(\n",
      "    (proj_proxy): Sequential(\n",
      "      (0): Linear(in_features=320, out_features=448, bias=True)\n",
      "      (1): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (patch_embed4): DownSamples(\n",
      "    (proj): Conv2d(320, 448, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (norm): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (block4): ModuleList(\n",
      "    (0-2): 3 x MergeBlock(\n",
      "      (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (q): Linear(in_features=448, out_features=448, bias=True)\n",
      "        (kv): Linear(in_features=448, out_features=896, bias=True)\n",
      "        (proj): Linear(in_features=448, out_features=448, bias=True)\n",
      "      )\n",
      "      (mlp): MergeFFN(\n",
      "        (fc1): Linear(in_features=448, out_features=1344, bias=True)\n",
      "        (dwconv): DWConv(\n",
      "          (dwconv): Conv2d(1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344)\n",
      "        )\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=1344, out_features=448, bias=True)\n",
      "        (fc_proxy): Sequential(\n",
      "          (0): Linear(in_features=448, out_features=896, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=896, out_features=448, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm4): LayerNorm((448,), eps=1e-06, elementwise_affine=True)\n",
      "  (post_network): ModuleList(\n",
      "    (0): ClassBlock(\n",
      "      (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): ClassAttention(\n",
      "        (kv): Linear(in_features=448, out_features=896, bias=True)\n",
      "        (q): Linear(in_features=448, out_features=448, bias=True)\n",
      "        (proj): Linear(in_features=448, out_features=448, bias=True)\n",
      "      )\n",
      "      (mlp): FFN(\n",
      "        (fc1): Linear(in_features=448, out_features=896, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=896, out_features=448, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Linear(in_features=448, out_features=1000, bias=True)\n",
      "  (aux_head): Linear(in_features=448, out_features=1000, bias=True)\n",
      ")\n",
      "Input image shape: torch.Size([1, 3, 224, 224])\n",
      "Model output shape: torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "from torch import nn\n",
    "\n",
    "# Define a function to simulate an image\n",
    "def simulate_image(batch_size=1, in_chans=3, height=224, width=224):\n",
    "    return torch.rand(batch_size, in_chans, height, width)\n",
    "\n",
    "# Instantiate the small DualViT model\n",
    "model = dualvit_s(pretrained=False)\n",
    "\n",
    "# Print model summary (optional)\n",
    "print(model)\n",
    "\n",
    "# Simulate a batch of input images\n",
    "input_image = simulate_image(batch_size=1, in_chans=3, height=224, width=224)\n",
    "print(\"Input image shape:\", input_image.shape)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Pass the simulated image through the model\n",
    "output = model(input_image)\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Model output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "\n",
      "Starting Testing...\n",
      "Testing Accuracy: 10.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from functools import partial\n",
    "\n",
    "# Assuming dualvit_s and simulate_image are already defined\n",
    "def dualvit_s(pretrained=False, **kwargs):\n",
    "    model = DualViT(\n",
    "        stem_hidden_dim=32,\n",
    "        embed_dims=[64, 128, 320, 448],\n",
    "        num_heads=[2, 4, 10, 14],\n",
    "        mlp_ratios=[8, 8, 4, 3, 2],\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6),\n",
    "        depths=[3, 4, 6, 3],\n",
    "        **kwargs)\n",
    "    return model\n",
    "\n",
    "def simulate_image(batch_size=1, in_chans=3, height=224, width=224):\n",
    "    return torch.rand(batch_size, in_chans, height, width)\n",
    "\n",
    "# Parameters\n",
    "num_classes = 10\n",
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instantiate model, loss function, and optimizer\n",
    "model = dualvit_s(num_classes=num_classes)\n",
    "model.train()  # Set to training mode\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Fake data loader\n",
    "def fake_data_loader(num_batches, batch_size, in_chans, height, width, num_classes):\n",
    "    for _ in range(num_batches):\n",
    "        images = simulate_image(batch_size, in_chans, height, width)\n",
    "        labels = torch.randint(0, num_classes, (batch_size,))\n",
    "        yield images, labels\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting Training...\")\n",
    "total_loss = 0\n",
    "for images, labels in fake_data_loader(10, batch_size, 3, 224, 224, num_classes):\n",
    "    optimizer.zero_grad()  # Clear gradients\n",
    "    outputs = model(images)  # Forward pass\n",
    "    \n",
    "    # Extract logits if the model returns a tuple\n",
    "    if isinstance(outputs, tuple):\n",
    "        logits = outputs[0]\n",
    "    else:\n",
    "        logits = outputs\n",
    "\n",
    "    loss = criterion(logits, labels)  # Compute loss\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update weights\n",
    "    total_loss += loss.item()\n",
    "\n",
    "\n",
    "# Testing loop\n",
    "print(\"\\nStarting Testing...\")\n",
    "model.eval()  # Set to evaluation mode\n",
    "num_correct = 0\n",
    "num_samples = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in fake_data_loader(5, batch_size, 3, 224, 224, num_classes):\n",
    "        outputs = model(images)\n",
    "        predictions = torch.argmax(outputs, dim=1)  # Get class with highest probability\n",
    "        num_correct += (predictions == labels).sum().item()\n",
    "        num_samples += labels.size(0)\n",
    "\n",
    "accuracy = num_correct / num_samples * 100\n",
    "print(f\"Testing Accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNvZZAbWdyrVsajb/IWKOwg",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
